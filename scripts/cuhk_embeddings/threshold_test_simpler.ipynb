{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7e2715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging.config\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from rescueclip.logging_config import LOGGING_CONFIG\n",
    "\n",
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "logger = logging.getLogger(__name__)\n",
    "from pathlib import Path\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from typing import cast, Sequence, List, Any, Literal\n",
    "import weaviate\n",
    "from tqdm import tqdm\n",
    "from weaviate.classes.query import Filter, MetadataQuery\n",
    "from weaviate.collections.classes.types import Properties, WeaviateProperties\n",
    "from weaviate.collections.classes.internal import Object\n",
    "from weaviate.util import generate_uuid5, get_vector\n",
    "\n",
    "from rescueclip import cuhk\n",
    "from rescueclip.cuhk import SetNumToImagesMap\n",
    "from rescueclip.ml_model import (\n",
    "    CollectionConfig,\n",
    "    CUHK_Apple_Collection,\n",
    "    CUHK_Google_Siglip_Base_Patch16_224_Collection,\n",
    "    CUHK_Google_Siglip_SO400M_Patch14_384_Collection,\n",
    "    CUHK_laion_CLIP_ViT_bigG_14_laion2B_39B_b160k_Collection,\n",
    "    CUHK_MetaCLIP_ViT_bigG_14_quickgelu_224_Collection,\n",
    "    CUHK_ViT_B_32_Collection,\n",
    ")\n",
    "from rescueclip.weaviate import WeaviateClientEnsureReady\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c785fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 02:21:32,631 [INFO] rescueclip.weaviate: Weaviate is ready\n",
      "2025-02-24 02:21:32,638 [INFO] __main__: Number of objects 18596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch3/atharva/anaconda3/envs/rescueCLIP/lib/python3.12/site-packages/weaviate/warnings.py:314: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "collection_config = CUHK_Apple_Collection\n",
    "client = WeaviateClientEnsureReady().get_client()\n",
    "collection = client.collections.get(collection_config.name)\n",
    "QUERY_MAXIMUM_RESULTS = 200_000\n",
    "\n",
    "number_of_objects: int = collection.aggregate.over_all(total_count=True).total_count # type: ignore\n",
    "logger.info(f\"Number of objects %s\", number_of_objects)\n",
    "assert (\n",
    "    number_of_objects <= QUERY_MAXIMUM_RESULTS \n",
    "), \"Ensure docker-compose.yml has QUERY_MAXIMUM_RESULTS to greater than 200_000 or the experiment's results may be inaccurate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9694d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 02:21:32,705 [INFO] __main__: Retrieving the entire database into memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch3/atharva/anaconda3/envs/rescueCLIP/lib/python3.12/asyncio/selector_events.py:879: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=71 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 02:21:36,220 [INFO] __main__: N: 18596\n",
      "2025-02-24 02:21:36,223 [INFO] __main__: X.shape: (18596, 1024)\n",
      "2025-02-24 02:21:36,223 [INFO] __main__: y_set_labels.shape: (18596,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "logger.info(\"Retrieving the entire database into memory\")\n",
    "objects = collection.query.fetch_objects(\n",
    "    limit=QUERY_MAXIMUM_RESULTS,\n",
    "    include_vector=True,\n",
    "    return_properties=True,\n",
    ").objects\n",
    "assert len(objects) == number_of_objects, \"Expected the entire database to be retrieved\"\n",
    "\n",
    "objects.sort(key=lambda obj: (obj.properties[\"set_number\"], obj.properties[\"file_name\"]))\n",
    "\n",
    "##### TEMPORARITY MAKE DATASET SMALLER\n",
    "# objects = objects[:512*4] # 4 sets of 4 images each\n",
    "#####\n",
    "\n",
    "# (N, D)\n",
    "X = np.array([obj.vector[\"embedding\"] for obj in objects])\n",
    "y_set_labels = np.array([obj.properties[\"set_number\"] for obj in objects])\n",
    "N = X.shape[0]\n",
    "logger.info(f\"N: {N}\")\n",
    "assert y_set_labels.shape[0] == N, \"Expected the number of objects to match the number of set labels\"\n",
    "\n",
    "##### TEMPORARITY ASSERTIONS\n",
    "# assert N == 512*4, \"Expected 16 objects\"\n",
    "# assert y_set_labels.shape[0] == 512*4, \"Expected 16 objects\"\n",
    "# assert (np.unique(y_set_labels) == np.array([1, 4, 8, 9])).all(), \"Expected the set labels to be 0, 1, 2, 3, got {}\".format(np.unique(y_set_labels))\n",
    "#####\n",
    "\n",
    "logger.info(f\"X.shape: {X.shape}\")\n",
    "logger.info(f\"y_set_labels.shape: {y_set_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151587a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 02:21:36,270 [INFO] __main__: X_train_vectors.shape: (9298, 1024)\n",
      "2025-02-24 02:21:36,271 [INFO] __main__: X_test_vectors.shape: (9298, 1024)\n"
     ]
    }
   ],
   "source": [
    "assert N % 2 == 0, \"Can't evenly split the data into train and test sets\"\n",
    "# (N//2, D)\n",
    "X_train_vectors = X[:N//2, :]\n",
    "# (N//2, D)\n",
    "X_test_vectors = X[N//2:, :]\n",
    "\n",
    "logger.info(f\"X_train_vectors.shape: {X_train_vectors.shape}\")\n",
    "logger.info(f\"X_test_vectors.shape: {X_test_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d241c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "X_train_distances = cdist(X_train_vectors, X_train_vectors, metric='cosine')\n",
    "y_train_labels = y_set_labels[:N//2]\n",
    "\n",
    "logger.info(\"X_train_distances.shape: {}\".format(X_train_distances.shape))\n",
    "logger.info(\"y_train_labels.shape: {}\".format(y_train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82bdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.15403616 0.1994384  0.37220493 0.31865613]\n",
      " [0.15403616 0.         0.12657806 0.34442987 0.36794799]\n",
      " [0.1994384  0.12657806 0.         0.28237242 0.30409882]\n",
      " [0.37220493 0.34442987 0.28237242 0.         0.35346233]\n",
      " [0.31865613 0.36794799 0.30409882 0.35346233 0.        ]]\n",
      "[1 1 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_distances[:5, :5])\n",
    "print(y_train_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c2f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 01:59:35,119 [INFO] __main__: X_test_distances.shape: (9298, 9298)\n",
      "2025-02-24 01:59:35,121 [INFO] __main__: y_test_labels.shape: (9298,)\n"
     ]
    }
   ],
   "source": [
    "X_test_distances = cdist(X_train_vectors, X_test_vectors, metric='cosine')\n",
    "y_test_labels = y_set_labels[N//2:]\n",
    "\n",
    "logger.info(f\"X_test_distances.shape: {X_test_distances.shape}\")\n",
    "logger.info(f\"y_test_labels.shape: {y_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80eb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del X\n",
    "    del y_set_labels\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91679ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1411  487 5636    1 5010 4696 7506]\n",
      " [   1 3491 3201 6317 2771 4297    2 5816]\n",
      " [   2 7489 8574 1484 3200 5817 4298 2025]\n",
      " [   3 3343 2050 3579 7767 6722 4007 5282]\n",
      " [   4 6900 4868 3822 4783 3076 7404 5922]\n",
      " [   5  373 6352    6 7279  372  224 6353]\n",
      " [   6 6353  224 5714    5  375 6354 6648]\n",
      " [   7 8971 3715 1959 1958 2262  227    4]]\n",
      "2025-02-24 01:59:36,552 [INFO] __main__: Fixing distances at positions: [2488 2793 2794 3399 5237 5416 5476 7725 8347 8945]\n",
      "2025-02-24 01:59:36,553 [INFO] __main__: Swapping index: 2488\n",
      "2025-02-24 01:59:36,554 [INFO] __main__: Swapping index: 2793\n",
      "2025-02-24 01:59:36,555 [INFO] __main__: Swapping index: 2794\n",
      "2025-02-24 01:59:36,555 [INFO] __main__: Swapping index: 3399\n",
      "2025-02-24 01:59:36,556 [INFO] __main__: Swapping index: 5237\n",
      "2025-02-24 01:59:36,556 [INFO] __main__: Swapping index: 5416\n",
      "2025-02-24 01:59:36,557 [INFO] __main__: Swapping index: 5476\n",
      "2025-02-24 01:59:36,558 [INFO] __main__: Swapping index: 7725\n",
      "2025-02-24 01:59:36,558 [INFO] __main__: Swapping index: 8347\n",
      "2025-02-24 01:59:36,559 [INFO] __main__: Swapping index: 8945\n",
      "[[0.         0.13958682 0.13997118 0.15222377 0.15403616]\n",
      " [0.         0.10714631 0.11320181 0.11871784 0.11988065]\n",
      " [0.         0.09534998 0.09605013 0.09625247 0.09760088]\n",
      " [0.         0.12970317 0.14966724 0.15309121 0.15827376]\n",
      " [0.         0.10677033 0.12087408 0.12126793 0.12196291]]\n",
      "[[   1  956  354 3917    1 3498 3293 5215]\n",
      " [   1 2407 2227 4413 1927 2999    1 4051]\n",
      " [   1 5200 5988 1003 2227 4051 2999 1387]\n",
      " [   1 2314 1401 2472 5401 4669 2786 3681]\n",
      " [   4 4822 3409 2648 3335 2131 5148 4117]\n",
      " [   4  281 4438    4 5070  281  162 4438]\n",
      " [   4 4438  162 3978    4  281 4438 4618]\n",
      " [   4 6250 2566 1345 1345 1555  162    4]]\n",
      "2025-02-24 01:59:37,564 [INFO] __main__: X_train_distances.shape: (9298, 9298)\n",
      "2025-02-24 01:59:37,565 [INFO] __main__: y_set_labels_mat.shape: (9298, 9298)\n"
     ]
    }
   ],
   "source": [
    "# For train data\n",
    "sorted_indexes = np.argsort(X_train_distances, axis=1)\n",
    "print(sorted_indexes[:8, :8])\n",
    "assertion_cond = (np.arange(N//2) == sorted_indexes[:, 0])\n",
    "if not np.all(assertion_cond):\n",
    "    false_indices = np.flatnonzero(~assertion_cond)\n",
    "    logger.info(f\"Fixing distances at positions: {false_indices}\")\n",
    "    for false_index in false_indices:\n",
    "        logger.info(f\"Swapping index: {false_index}\")\n",
    "        temp = sorted_indexes[false_index, 0]\n",
    "        sorted_indexes[false_index, 0] = sorted_indexes[false_index, 1]\n",
    "        sorted_indexes[false_index, 1] = temp\n",
    "    assertion_cond = (np.arange(N//2) == sorted_indexes[:, 0])\n",
    "    if not np.all(assertion_cond):\n",
    "        false_indices = np.flatnonzero(~assertion_cond)\n",
    "        assert False, f\"Expected the first column of the sorted indexes to be the same as the original indexes\\n{false_indices=}\\n{sorted_indexes[false_indices[0] - 3:false_indices[0] + 3, :]=}\"\n",
    "\n",
    "X_train_distances = np.take_along_axis(X_train_distances, sorted_indexes, axis=1)\n",
    "y_train_labels_mat = y_train_labels[sorted_indexes]\n",
    "del sorted_indexes\n",
    "print(X_train_distances[:5, :5])\n",
    "print(y_train_labels_mat[:8, :8])\n",
    "\n",
    "logger.info(f\"X_train_distances.shape: {X_train_distances.shape}\")\n",
    "logger.info(f\"y_set_labels_mat.shape: {y_train_labels_mat.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17dcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 226  429 4441 1757 2181 5471 5530 1528]\n",
      " [7124 4798 4829 8898 8286 7123 3091 8287]\n",
      " [2703 3112 2968 8671 4109 5355 4799 4511]\n",
      " [3705 7361 7437 3756 6849 8080 5651 8985]\n",
      " [6745 6055 6742 9248 4598 9152 1633 1632]\n",
      " [4286 5566 6743 8423 1630 2090 9246 1347]\n",
      " [4288  655 1632 9247 4789 2091 1630 8424]\n",
      " [6205 5145 4742 6204 6745  145 1632 4601]]\n",
      "[[0.14270019 0.15325238 0.15865978 0.16644472 0.16734573]\n",
      " [0.10827802 0.11412352 0.12063116 0.12216119 0.12355196]\n",
      " [0.07889354 0.09941126 0.10033786 0.10130416 0.10301782]\n",
      " [0.14301369 0.15255575 0.15456978 0.16176671 0.16790703]\n",
      " [0.09705455 0.09755191 0.09822653 0.10485656 0.10847885]]\n",
      "[[ 6630  6777  9683  7768  8082 10388 10422  7579]\n",
      " [11531  9929  9957 12717 12271 11531  8690 12271]\n",
      " [ 8428  8708  8599 12543  9446 10302  9929  9737]\n",
      " [ 9152 11675 11732  9193 11387 12157 10531 12792]\n",
      " [11320 10810 11320 12966  9795 12901  7658  7658]\n",
      " [ 9581 10456 11320 12367  7658  8020 12966  7449]\n",
      " [ 9581  6928  7658 12966  9914  8020  7658 12367]\n",
      " [10922 10168  9893 10922 11320  6585  7658  9795]]\n",
      "2025-02-24 01:59:39,924 [INFO] __main__: X_test_distances.shape: (9298, 9298)\n",
      "2025-02-24 01:59:39,925 [INFO] __main__: y_test_labels_mat.shape: (9298, 9298)\n"
     ]
    }
   ],
   "source": [
    "# For test distances\n",
    "sorted_indexes = np.argsort(X_test_distances, axis=1)\n",
    "print(sorted_indexes[:8, :8])\n",
    "\n",
    "X_test_distances = np.take_along_axis(X_test_distances, sorted_indexes, axis=1)\n",
    "y_test_labels_mat = y_test_labels[sorted_indexes]\n",
    "del sorted_indexes\n",
    "print(X_test_distances[:5, :5])\n",
    "print(y_test_labels_mat[:8, :8])\n",
    "\n",
    "logger.info(f\"X_test_distances.shape: {X_test_distances.shape}\")\n",
    "logger.info(f\"y_test_labels_mat.shape: {y_test_labels_mat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_result_naive(X, y_set_labels_mat, y_set_labels, t, is_train: bool):\n",
    "    N = X.shape[0]\n",
    "    result = np.zeros(N, dtype=int)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Since X[i] is sorted in ascending order, find the cutoff index.\n",
    "        # This returns the index at which t should be inserted to maintain order,\n",
    "        # meaning all indices below this are <= t.\n",
    "        k = np.searchsorted(X[i], t, side='right')\n",
    "        \n",
    "        # Get the labels for these positions\n",
    "        selected_labels = y_set_labels_mat[i, :k]\n",
    "        \n",
    "        # Count how many times the label equals y_set_labels[i]\n",
    "        count = np.sum(selected_labels == y_set_labels[i])\n",
    "\n",
    "        # If is train, and t is suffiently large, make sure than the count is at least 1\n",
    "        if is_train and t > 0.05:\n",
    "            assert count >= 1, f\"count: {count}, t: {t}, i: {i}, k: {k}\"\n",
    "        \n",
    "        # If the count is at least 2, set result[i] to 1\n",
    "        if count >= 2:\n",
    "            result[i] = 1\n",
    "            \n",
    "    return result\n",
    "\n",
    "def compute_result_vectorized(X, y_set_labels_mat, y_set_labels, t, is_train):\n",
    "    # Create a mask where each element is True if X[i, j] <= t.\n",
    "    mask_threshold = X <= t  # shape (N, N)\n",
    "    \n",
    "    # Create a mask where each element is True if y_set_labels_mat[i, j] equals y_set_labels[i].\n",
    "    label_match = (y_set_labels_mat == y_set_labels[:, np.newaxis])\n",
    "    \n",
    "    # Combine the masks to consider only the positions meeting both conditions.\n",
    "    combined_mask = mask_threshold & label_match\n",
    "    \n",
    "    # Count the matches in each row.\n",
    "    count = np.sum(combined_mask, axis=1)\n",
    "\n",
    "    # If is train, and t is suffiently large, make sure than the count is at least 1\n",
    "    if is_train and t > 0.05:\n",
    "        assertion_cond = count >= 1\n",
    "        if not np.all(assertion_cond):\n",
    "            false_indices = np.flatnonzero(~assertion_cond)\n",
    "            assert False, f\"count: {count}, t: {t}, at index: {false_indices[0]}\"\n",
    "    \n",
    "    # Result is 1 if count >= 2, else 0.\n",
    "    result = (count >= 2).astype(int)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ConfusionMatrix:\n",
    "    tp: int | np.floating = 0\n",
    "    tn: int | np.floating = 0\n",
    "    fp: int | np.floating = 0\n",
    "    fn: int | np.floating = 0\n",
    "\n",
    "    def update(self, *, tp: int | np.floating = 0, tn: int | np.floating = 0, fp: int | np.floating = 0, fn: int | np.floating = 0):\n",
    "        self.tp += tp\n",
    "        self.tn += tn\n",
    "        self.fp += fp\n",
    "        self.fn += fn\n",
    "\n",
    "    def as_array(self):\n",
    "        # Returns a 2x2 array: [[tn, fp], [fn, tp]]\n",
    "        return [[self.tn, self.fp], [self.fn, self.tp]]\n",
    "    \n",
    "    # how often predictions for the positive class are correct\n",
    "    def precision(self):\n",
    "        if self.tp + self.fp == 0:\n",
    "            return 0.0\n",
    "        return self.tp / (self.tp + self.fp)\n",
    "\n",
    "    # proportion of all actual positives (in the DB) that were classified correctly as positives\n",
    "    def recall(self):\n",
    "        if self.tp + self.fn == 0:\n",
    "            return 0.0\n",
    "        return self.tp / (self.tp + self.fn)\n",
    "\n",
    "    def f1(self):\n",
    "        prec = self.precision()\n",
    "        rec = self.recall()\n",
    "        if prec + rec == 0:\n",
    "            return 0.0\n",
    "        return 2 * (prec * rec) / (prec + rec)\n",
    "    \n",
    "    # the probability of a test incorrectly identifying a negative result (not in DB) as positive\n",
    "    def fpr(self):\n",
    "        if self.fp + self.tn == 0:\n",
    "            return 0.0\n",
    "        return self.fp / (self.fp + self.tn)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"TP: {self.tp}, TN: {self.tn}, FP: {self.fp}, FN: {self.fn}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_test(t, X_train_distances, y_train_labels_mat, y_train_labels, X_test_distances, y_test_labels_mat, y_test_labels) -> ConfusionMatrix:\n",
    "    # Training results\n",
    "    training_set_results = compute_result_naive(X_train_distances, y_train_labels_mat, y_train_labels, t, True)\n",
    "    assert training_set_results.shape[0] == X_train_distances.shape[0] == y_train_labels_mat.shape[0] == y_train_labels.shape[0], f\"Dimension check failed {training_set_results.shape[0]=} {X_train_distances.shape[0]=} {y_train_labels_mat.shape[0]=} {y_train_labels.shape[0]=}\"\n",
    "\n",
    "    training_counts = np.unique_counts(training_set_results)\n",
    "    assert len(training_counts.counts) <= 2, f\"Expected <= 2 values, got {training_counts}\"\n",
    "\n",
    "    # Testing results\n",
    "    test_set_results = compute_result_naive(X_test_distances, y_test_labels_mat, y_test_labels, t, False)\n",
    "    assert test_set_results.shape[0] == X_test_distances.shape[0] == y_test_labels_mat.shape[0] == y_test_labels.shape[0], f\"Dimension check failed {test_set_results.shape[0]=} {X_test_distances.shape[0]=} {y_test_labels_mat.shape[0]=} {y_test_labels.shape[0]=}\"\n",
    "\n",
    "    testing_counts = np.unique_counts(test_set_results)\n",
    "    assert len(testing_counts.counts) <= 2, f\"Expected <= 2 values, got {testing_counts}\"\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = ConfusionMatrix()\n",
    "    if len(training_counts.counts) == 2:\n",
    "        tp = training_counts.counts[1]\n",
    "        fn = training_counts.counts[0]\n",
    "    elif len(training_counts.counts) == 1:\n",
    "        count_for = training_counts.values[0]\n",
    "        if count_for == 1:\n",
    "            tp = training_counts.counts[0]\n",
    "            fn = 0\n",
    "        elif count_for == 0:\n",
    "            tp = 0\n",
    "            fn = training_counts.counts[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected value {count_for}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected value {training_counts}\")\n",
    "\n",
    "    if len(testing_counts.counts) == 2:\n",
    "        tn = testing_counts.counts[0]\n",
    "        fp = testing_counts.counts[1]\n",
    "    elif len(testing_counts.counts) == 1:\n",
    "        count_for = testing_counts.values[0]\n",
    "        if count_for == 1:\n",
    "            fp = testing_counts.counts[0]\n",
    "            tn = 0\n",
    "        elif count_for == 0:\n",
    "            fp = 0\n",
    "            tn = testing_counts.counts[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected value {count_for}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected value {testing_counts}\")\n",
    "\n",
    "    cm.update(tp=tp, tn=tn, fp=fp, fn=fn)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fb939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 02:15:43,776 [INFO] __main__: Threshold: 0.2\n",
      "2025-02-24 02:15:43,777 [INFO] __main__: Time taken: 0.20541620254516602\n",
      "2025-02-24 02:15:43,778 [INFO] __main__: TP: 8789, TN: 8415, FP: 883, FN: 509\n",
      "2025-02-24 02:15:43,778 [INFO] __main__: Precision: 0.9087055417700579\n",
      "2025-02-24 02:15:43,779 [INFO] __main__: Recall: 0.9452570445257045\n",
      "2025-02-24 02:15:43,779 [INFO] __main__: FPR: 0.09496665949666595\n",
      "2025-02-24 02:15:43,780 [INFO] __main__: F1: 0.9266209804955193\n"
     ]
    }
   ],
   "source": [
    "# Smoke test\n",
    "t = 0.2\n",
    "tic = time.time()\n",
    "cm = threshold_test(t, X_train_distances, y_train_labels_mat, y_train_labels, X_test_distances, y_test_labels_mat, y_test_labels)\n",
    "toc = time.time()\n",
    "logger.info(f\"Threshold: {t}\")\n",
    "logger.info(f\"Time taken: {toc - tic}\")\n",
    "logger.info(f\"{cm}\")\n",
    "logger.info(f\"Precision: {cm.precision()}\")\n",
    "logger.info(f\"Recall: {cm.recall()}\")\n",
    "logger.info(f\"FPR: {cm.fpr()}\")\n",
    "logger.info(f\"F1: {cm.f1()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:02<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "results: dict[float, ConfusionMatrix] = {}\n",
    "N_THRESHOLDS = 400\n",
    "for t in tqdm(np.linspace(0, 1, N_THRESHOLDS), total=N_THRESHOLDS):\n",
    "    cm = threshold_test(t, X_train_distances, y_train_labels_mat, y_train_labels, X_test_distances, y_test_labels_mat, y_test_labels)\n",
    "    results[t] = cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e8e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds: 400\n",
      "TPR: 400\n",
      "FPR: 400\n",
      "Best F1 score: 0.9287925696594428\n",
      "Best threshold: 0.19298245614035087\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc  # Alternatively, use np.trapz for AUC calculation\n",
    "\n",
    "# Extract FPR and TPR for each threshold.\n",
    "# Note: Sorting the thresholds ensures the curve is plotted in order.\n",
    "thresholds = sorted(results.keys())\n",
    "\n",
    "tpr_list = np.array([results[t].recall() for t in thresholds])\n",
    "fpr_list = np.array([results[t].fpr() for t in thresholds])\n",
    "f1_scores = np.array([results[t].f1() for t in thresholds])\n",
    "\n",
    "print(f\"Thresholds: {len(thresholds)}\")\n",
    "print(f\"TPR: {len(tpr_list)}\")\n",
    "print(f\"FPR: {len(fpr_list)}\")\n",
    "print(f\"Best F1 score: {np.max(f1_scores)}\")\n",
    "print(f\"Best threshold: {thresholds[np.argmax(f1_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3db93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_violations(value_list, increasing=True):\n",
    "    violations = []\n",
    "\n",
    "    for i in range(1, len(value_list)):\n",
    "        if increasing:\n",
    "            if value_list[i] < value_list[i - 1]:\n",
    "                violations.append(i)\n",
    "        else:\n",
    "            if value_list[i] > value_list[i - 1]:\n",
    "                violations.append(i)\n",
    "    if not violations:\n",
    "        return False\n",
    "    else:\n",
    "        for i in violations:\n",
    "            print(f\"Violation at index {i}: fpr_list[{i}] = {fpr_list[i]}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_violations(fpr_list, True):\n",
    "    print(\"Violations found for FPR list\")\n",
    "if has_violations(tpr_list, True):\n",
    "    print(\"Violations found for TPR list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7575c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute the Area Under the Curve (AUC)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m \u001b[43mauc\u001b[49m(fpr_list, tpr_list)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the ROC curve\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auc' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute the Area Under the Curve (AUC)\n",
    "roc_auc = auc(fpr_list, tpr_list)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_list, tpr_list, lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='gray', label='Random Guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rescueCLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
